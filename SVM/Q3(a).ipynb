{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dual SVM and comparing with Primal SVM results:\n",
      "\n",
      "C\tTrain Error\tTest Error\t#Support Vectors\n",
      "------------------------------------------------------------\n",
      "0.1145\t0.0505\t\t0.0480\t\t664\n",
      "\n",
      "Weight vector norm: 0.4603\n",
      "Bias term: 0.4188\n",
      "0.5727\t0.0722\t\t0.0860\t\t784\n",
      "\n",
      "Weight vector norm: 0.5023\n",
      "Bias term: 0.4418\n",
      "0.8018\t0.0631\t\t0.0660\t\t790\n",
      "\n",
      "Weight vector norm: 0.4978\n",
      "Bias term: 0.4419\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "class DualSVM:\n",
    "    def __init__(self, C: float):\n",
    "        \"\"\"\n",
    "        Initialize Dual SVM.\n",
    "        \n",
    "        Args:\n",
    "            C: Regularization parameter\n",
    "        \"\"\"\n",
    "        self.C = C\n",
    "        self.alphas = None  # Lagrange multipliers\n",
    "        self.w = None       # Weight vector\n",
    "        self.b = 0         # Bias term\n",
    "        self.support_vectors = None\n",
    "        self.support_vector_labels = None\n",
    "        self.support_vector_indices = None\n",
    "        \n",
    "    def _compute_kernel(self, X1: np.ndarray, X2: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute linear kernel between X1 and X2.\"\"\"\n",
    "        return np.dot(X1, X2.T)\n",
    "    \n",
    "    def _objective(self, alphas: np.ndarray, K: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Compute the dual objective function.\n",
    "        \n",
    "        Args:\n",
    "            alphas: Lagrange multipliers\n",
    "            K: Kernel matrix\n",
    "            y: Labels\n",
    "        \n",
    "        Returns:\n",
    "            Objective value\n",
    "        \"\"\"\n",
    "        return -np.sum(alphas) + 0.5 * np.sum(y.reshape(-1,1) * y * K * alphas.reshape(-1,1) * alphas)\n",
    "    \n",
    "    def _objective_gradient(self, alphas: np.ndarray, K: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute gradient of the dual objective.\"\"\"\n",
    "        return -np.ones_like(alphas) + (y.reshape(-1,1) * y * K * alphas.reshape(-1,1)).sum(axis=1)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Train the SVM using dual formulation.\n",
    "        \n",
    "        Args:\n",
    "            X: Training features (n_samples, n_features)\n",
    "            y: Training labels {-1, 1} (n_samples,)\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Compute kernel matrix\n",
    "        K = self._compute_kernel(X, X)\n",
    "        \n",
    "        # Define constraints for optimization\n",
    "        constraints = [\n",
    "            {'type': 'eq', 'fun': lambda a: np.dot(a, y)},  # Sum(alpha_i * y_i) = 0\n",
    "        ]\n",
    "        \n",
    "        # Box constraints: 0 <= alpha_i <= C\n",
    "        bounds = [(0, self.C) for _ in range(n_samples)]\n",
    "        \n",
    "        # Initialize alphas\n",
    "        alpha0 = np.zeros(n_samples)\n",
    "        \n",
    "        # Solve dual optimization problem\n",
    "        result = minimize(\n",
    "            fun=lambda a: self._objective(a, K, y),\n",
    "            x0=alpha0,\n",
    "            method='SLSQP',\n",
    "            jac=lambda a: self._objective_gradient(a, K, y),\n",
    "            bounds=bounds,\n",
    "            constraints=constraints\n",
    "        )\n",
    "        \n",
    "        self.alphas = result.x\n",
    "        \n",
    "        # Find support vectors (alphas > 1e-4)\n",
    "        sv_indices = np.where(self.alphas > 1e-4)[0]\n",
    "        self.support_vector_indices = sv_indices\n",
    "        self.support_vectors = X[sv_indices]\n",
    "        self.support_vector_labels = y[sv_indices]\n",
    "        \n",
    "        # Compute w and b\n",
    "        self.w = np.sum(self.alphas.reshape(-1, 1) * y.reshape(-1, 1) * X, axis=0)\n",
    "        \n",
    "        # Compute b using support vectors\n",
    "        margins = np.dot(self.support_vectors, self.w)\n",
    "        self.b = np.mean(self.support_vector_labels - margins)\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Make predictions for test data.\"\"\"\n",
    "        return np.sign(np.dot(X, self.w) + self.b)\n",
    "    \n",
    "    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"Calculate accuracy score.\"\"\"\n",
    "        return np.mean(self.predict(X) == y)\n",
    "\n",
    "def load_and_preprocess_data(train_path: str, test_path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Load and preprocess the banknote data.\"\"\"\n",
    "    train_data = np.loadtxt(train_path, delimiter=',')\n",
    "    test_data = np.loadtxt(test_path, delimiter=',')\n",
    "    \n",
    "    X_train, y_train = train_data[:, :-1], train_data[:, -1]\n",
    "    X_test, y_test = test_data[:, :-1], test_data[:, -1]\n",
    "    \n",
    "    # Convert labels to {-1, 1}\n",
    "    y_train = 2 * y_train - 1\n",
    "    y_test = 2 * y_test - 1\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    X_train, y_train, X_test, y_test = load_and_preprocess_data('train.csv', 'test.csv')\n",
    "    \n",
    "    # Define C values to test\n",
    "    C_values = [100/873, 500/873, 700/873]\n",
    "    \n",
    "    print(\"Training Dual SVM and comparing with Primal SVM results:\")\n",
    "    print(\"\\nC\\tTrain Error\\tTest Error\\t#Support Vectors\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for C in C_values:\n",
    "        # Train dual SVM\n",
    "        svm = DualSVM(C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        \n",
    "        # Calculate errors\n",
    "        train_error = 1 - svm.score(X_train, y_train)\n",
    "        test_error = 1 - svm.score(X_test, y_test)\n",
    "        n_support = len(svm.support_vector_indices)\n",
    "        \n",
    "        print(f\"{C:.4f}\\t{train_error:.4f}\\t\\t{test_error:.4f}\\t\\t{n_support}\")\n",
    "        \n",
    "        # Print weight vector for comparison with primal SVM\n",
    "        print(f\"\\nWeight vector norm: {np.linalg.norm(svm.w):.4f}\")\n",
    "        print(f\"Bias term: {svm.b:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
