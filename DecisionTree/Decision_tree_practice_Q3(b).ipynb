{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, attribute=None, threshold=None, label=None, branches=None):\n",
    "        self.attribute = attribute\n",
    "        self.threshold = threshold\n",
    "        self.label = label\n",
    "        self.branches = branches or {}\n",
    "\n",
    "def id3(data, attributes, label_index, max_depth, criterion='info_gain'):\n",
    "    labels = [row[label_index] for row in data]\n",
    "    \n",
    "    if not labels:\n",
    "        return Node(label=None)\n",
    "    \n",
    "    if len(set(labels)) == 1:\n",
    "        return Node(label=labels[0])\n",
    "    if len(attributes) == 0 or max_depth == 0:\n",
    "        return Node(label=max(set(labels), key=labels.count))\n",
    "    \n",
    "    best_attribute, threshold = choose_best_attribute(data, attributes, label_index, criterion)\n",
    "    node = Node(attribute=best_attribute, threshold=threshold)\n",
    "    \n",
    "    if threshold is not None:\n",
    "        left_subset = [row for row in data if row[best_attribute] <= threshold]\n",
    "        right_subset = [row for row in data if row[best_attribute] > threshold]\n",
    "        if left_subset:\n",
    "            node.branches[f\"<={threshold}\"] = id3(left_subset, attributes, label_index, max_depth - 1, criterion)\n",
    "        if right_subset:\n",
    "            node.branches[f\">{threshold}\"] = id3(right_subset, attributes, label_index, max_depth - 1, criterion)\n",
    "    else:\n",
    "        for value in set(row[best_attribute] for row in data if row[best_attribute] != 'unknown'):\n",
    "            subset = [row for row in data if row[best_attribute] == value]\n",
    "            if subset:\n",
    "                node.branches[value] = id3(subset, attributes, label_index, max_depth - 1, criterion)\n",
    "    \n",
    "    if not node.branches:\n",
    "        return Node(label=max(set(labels), key=labels.count))\n",
    "    \n",
    "    return node\n",
    "\n",
    "def choose_best_attribute(data, attributes, label_index, criterion):\n",
    "    best_gain = -float('inf')\n",
    "    best_attribute = None\n",
    "    best_threshold = None\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        if all(isinstance(row[attribute], (int, float)) for row in data if row[attribute] != 'unknown'):\n",
    "            values = [row[attribute] for row in data if row[attribute] != 'unknown']\n",
    "            threshold = statistics.median(values)\n",
    "            gain = calculate_gain(data, attribute, label_index, criterion, threshold)\n",
    "        else:\n",
    "            gain = calculate_gain(data, attribute, label_index, criterion)\n",
    "            threshold = None\n",
    "        \n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_attribute = attribute\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_attribute, best_threshold\n",
    "\n",
    "def calculate_gain(data, attribute, label_index, criterion, threshold=None):\n",
    "    if criterion == 'info_gain':\n",
    "        return information_gain(data, attribute, label_index, threshold)\n",
    "    elif criterion == 'majority_error':\n",
    "        return majority_error(data, attribute, label_index, threshold)\n",
    "    elif criterion == 'gini_index':\n",
    "        return gini_index(data, attribute, label_index, threshold)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid criterion. Choose 'info_gain', 'majority_error', or 'gini_index'.\")\n",
    "\n",
    "def entropy(data, label_index):\n",
    "    labels = [row[label_index] for row in data]\n",
    "    counts = Counter(labels)\n",
    "    total = len(labels)\n",
    "    return -sum((count / total) * math.log2(count / total) for count in counts.values())\n",
    "\n",
    "def information_gain(data, attribute, label_index, threshold=None):\n",
    "    total_entropy = entropy(data, label_index)\n",
    "    weighted_entropy = 0\n",
    "    \n",
    "    if threshold is not None:\n",
    "        left_subset = [row for row in data if row[attribute] <= threshold]\n",
    "        right_subset = [row for row in data if row[attribute] > threshold]\n",
    "        weighted_entropy = (len(left_subset) / len(data)) * entropy(left_subset, label_index) + \\\n",
    "                           (len(right_subset) / len(data)) * entropy(right_subset, label_index)\n",
    "    else:\n",
    "        for value in set(row[attribute] for row in data):\n",
    "            subset = [row for row in data if row[attribute] == value]\n",
    "            weight = len(subset) / len(data)\n",
    "            weighted_entropy += weight * entropy(subset, label_index)\n",
    "    \n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def majority_error(data, attribute, label_index, threshold=None):\n",
    "    total_error = 1 - max(Counter(row[label_index] for row in data).values()) / len(data)\n",
    "    weighted_error = 0\n",
    "    \n",
    "    if threshold is not None:\n",
    "        # Binary split for numerical attributes\n",
    "        left_subset = [row for row in data if row[attribute] <= threshold]\n",
    "        right_subset = [row for row in data if row[attribute] > threshold]\n",
    "        left_error = 1 - max(Counter(row[label_index] for row in left_subset).values()) / len(left_subset) if left_subset else 0\n",
    "        right_error = 1 - max(Counter(row[label_index] for row in right_subset).values()) / len(right_subset) if right_subset else 0\n",
    "        weighted_error = (len(left_subset) / len(data)) * left_error + (len(right_subset) / len(data)) * right_error\n",
    "    else:\n",
    "        # Categorical split\n",
    "        for value in set(row[attribute] for row in data):\n",
    "            subset = [row for row in data if row[attribute] == value]\n",
    "            weight = len(subset) / len(data)\n",
    "            majority_class = max(set(row[label_index] for row in subset), key=lambda c: sum(1 for row in subset if row[label_index] == c))\n",
    "            error = sum(1 for row in subset if row[label_index] != majority_class) / len(subset)\n",
    "            weighted_error += weight * error\n",
    "    \n",
    "    return total_error - weighted_error\n",
    "\n",
    "def gini_index(data, attribute, label_index, threshold=None):\n",
    "    def calculate_gini(subset):\n",
    "        counts = Counter(row[label_index] for row in subset)\n",
    "        total = len(subset)\n",
    "        return 1 - sum((count / total) ** 2 for count in counts.values())\n",
    "\n",
    "    total_gini = calculate_gini(data)\n",
    "    weighted_gini = 0\n",
    "    \n",
    "    if threshold is not None:\n",
    "        left_subset = [row for row in data if row[attribute] <= threshold]\n",
    "        right_subset = [row for row in data if row[attribute] > threshold]\n",
    "        weighted_gini = (len(left_subset) / len(data)) * calculate_gini(left_subset) + \\\n",
    "                        (len(right_subset) / len(data)) * calculate_gini(right_subset)\n",
    "    else:\n",
    "        for value in set(row[attribute] for row in data):\n",
    "            subset = [row for row in data if row[attribute] == value]\n",
    "            weight = len(subset) / len(data)\n",
    "            weighted_gini += weight * calculate_gini(subset)\n",
    "    \n",
    "    return total_gini - weighted_gini\n",
    "\n",
    "def predict(node, instance):\n",
    "    if node.label is not None:\n",
    "        return node.label\n",
    "    if node.attribute >= len(instance):\n",
    "        return None\n",
    "    value = instance[node.attribute]\n",
    "    if node.threshold is not None:\n",
    "        if value == 'unknown':\n",
    "            return None\n",
    "        if value <= node.threshold:\n",
    "            branch = f\"<={node.threshold}\"\n",
    "        else:\n",
    "            branch = f\">{node.threshold}\"\n",
    "    else:\n",
    "        branch = value\n",
    "    if branch not in node.branches:\n",
    "        return None\n",
    "    return predict(node.branches[branch], instance)\n",
    "\n",
    "def load_data(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            instance = []\n",
    "            for value in row:\n",
    "                try:\n",
    "                    instance.append(float(value))\n",
    "                except ValueError:\n",
    "                    instance.append(value)\n",
    "            data.append(instance)\n",
    "    return data\n",
    "\n",
    "def replace_unknown(train_data, test_data):\n",
    "    for attr in range(len(train_data[0]) - 1): \n",
    "        values = [row[attr] for row in train_data if row[attr] != 'unknown']\n",
    "        if values:\n",
    "            majority = max(set(values), key=values.count)\n",
    "            for row in train_data:\n",
    "                if row[attr] == 'unknown':\n",
    "                    row[attr] = majority\n",
    "            for row in test_data:\n",
    "                if row[attr] == 'unknown':\n",
    "                    row[attr] = majority\n",
    "    return train_data, test_data\n",
    "\n",
    "def calculate_error(tree, data, label_index):\n",
    "    incorrect = sum(1 for instance in data if predict(tree, instance) != instance[label_index])\n",
    "    return incorrect / len(data)\n",
    "\n",
    "def run_experiment(train_data, test_data, max_depths, criteria):\n",
    "    num_attributes = len(train_data[0]) - 1\n",
    "    attributes = list(range(num_attributes))\n",
    "    label_index = -1\n",
    "    \n",
    "    results = {criterion: {depth: {'train': 0, 'test': 0} for depth in max_depths} for criterion in criteria}\n",
    "    \n",
    "    for criterion in criteria:\n",
    "        for depth in max_depths:\n",
    "            tree = id3(train_data, attributes, label_index, depth, criterion)\n",
    "            train_error = calculate_error(tree, train_data, label_index)\n",
    "            test_error = calculate_error(tree, test_data, label_index)\n",
    "            results[criterion][depth]['train'] = train_error\n",
    "            results[criterion][depth]['test'] = test_error\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth | Information Gain | Majority Error | Gini Index\n",
      "      | Train  | Test    | Train  | Test   | Train | Test\n",
      "------|--------|---------|--------|--------|-------|------\n",
      "    1 | 0.1192 | 0.1248 | 0.1088 | 0.1166 | 0.1088 | 0.1166\n",
      "    2 | 0.1060 | 0.1114 | 0.1074 | 0.1148 | 0.1080 | 0.1156\n",
      "    3 | 0.1042 | 0.1156 | 0.1002 | 0.1154 | 0.1002 | 0.1242\n",
      "    4 | 0.0934 | 0.1298 | 0.0910 | 0.1234 | 0.0932 | 0.1286\n",
      "    5 | 0.0796 | 0.1290 | 0.0796 | 0.1340 | 0.0828 | 0.1302\n",
      "    6 | 0.0650 | 0.1372 | 0.0682 | 0.1428 | 0.0682 | 0.1414\n",
      "    7 | 0.0418 | 0.1532 | 0.0616 | 0.1468 | 0.0436 | 0.1540\n",
      "    8 | 0.0218 | 0.1632 | 0.0546 | 0.1550 | 0.0244 | 0.1652\n",
      "    9 | 0.0102 | 0.1698 | 0.0502 | 0.1602 | 0.0114 | 0.1698\n",
      "   10 | 0.0040 | 0.1678 | 0.0470 | 0.1614 | 0.0042 | 0.1686\n",
      "   11 | 0.0010 | 0.1684 | 0.0460 | 0.1620 | 0.0010 | 0.1694\n",
      "   12 | 0.0008 | 0.1682 | 0.0452 | 0.1636 | 0.0002 | 0.1694\n",
      "   13 | 0.0000 | 0.1682 | 0.0452 | 0.1636 | 0.0000 | 0.1694\n",
      "   14 | 0.0000 | 0.1682 | 0.0452 | 0.1636 | 0.0000 | 0.1694\n",
      "   15 | 0.0000 | 0.1682 | 0.0452 | 0.1636 | 0.0000 | 0.1694\n",
      "   16 | 0.0000 | 0.1682 | 0.0452 | 0.1636 | 0.0000 | 0.1694\n"
     ]
    }
   ],
   "source": [
    "train_data = load_data('train_bank.csv')\n",
    "test_data = load_data('test_bank.csv')\n",
    "train_data, test_data = replace_unknown(train_data, test_data)\n",
    "\n",
    "max_depths = range(1, 17)\n",
    "criteria = ['info_gain', 'majority_error', 'gini_index']\n",
    "results = run_experiment(train_data, test_data, max_depths, criteria)\n",
    "\n",
    "print(\"Depth | Information Gain | Majority Error | Gini Index\")\n",
    "print(\"      | Train  | Test    | Train  | Test   | Train | Test\")\n",
    "print(\"------|--------|---------|--------|--------|-------|------\")\n",
    "for depth in max_depths:\n",
    "    print(f\"{depth:5d} | {results['info_gain'][depth]['train']:.4f} | {results['info_gain'][depth]['test']:.4f} | \"\n",
    "          f\"{results['majority_error'][depth]['train']:.4f} | {results['majority_error'][depth]['test']:.4f} | \"\n",
    "          f\"{results['gini_index'][depth]['train']:.4f} | {results['gini_index'][depth]['test']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
