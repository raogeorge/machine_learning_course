{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, attribute=None, threshold=None, label=None, branches=None):\n",
    "        self.attribute = attribute\n",
    "        self.threshold = threshold\n",
    "        self.label = label\n",
    "        self.branches = branches or {}\n",
    "\n",
    "def entropy(data, label_index):\n",
    "    labels = [row[label_index] for row in data]\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts / len(labels)\n",
    "    return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "\n",
    "def information_gain(data, attribute, label_index, criterion='info_gain'):\n",
    "    total_entropy = entropy(data, label_index)\n",
    "    weighted_entropy = 0\n",
    "    \n",
    "    if isinstance(data[0][attribute], (int, float)):\n",
    "        values = [float(row[attribute]) for row in data if row[attribute] != 'unknown']\n",
    "        threshold = np.median(values)\n",
    "        left_subset = [row for row in data if row[attribute] != 'unknown' and float(row[attribute]) <= threshold]\n",
    "        right_subset = [row for row in data if row[attribute] != 'unknown' and float(row[attribute]) > threshold]\n",
    "        \n",
    "        if left_subset:\n",
    "            weighted_entropy += len(left_subset) / len(data) * entropy(left_subset, label_index)\n",
    "        if right_subset:\n",
    "            weighted_entropy += len(right_subset) / len(data) * entropy(right_subset, label_index)\n",
    "    else:\n",
    "        for value in set(row[attribute] for row in data if row[attribute] != 'unknown'):\n",
    "            subset = [row for row in data if row[attribute] == value]\n",
    "            weighted_entropy += len(subset) / len(data) * entropy(subset, label_index)\n",
    "    \n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def choose_best_attribute(data, attributes, label_index, criterion='info_gain'):\n",
    "    best_gain = -float('inf')\n",
    "    best_attribute = None\n",
    "    best_threshold = None\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        gain = information_gain(data, attribute, label_index, criterion)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_attribute = attribute\n",
    "            if isinstance(data[0][attribute], (int, float)):\n",
    "                values = [float(row[attribute]) for row in data if row[attribute] != 'unknown']\n",
    "                best_threshold = np.median(values)\n",
    "    \n",
    "    return best_attribute, best_threshold\n",
    "\n",
    "def id3(data, attributes, label_index, max_depth, criterion='info_gain'):\n",
    "    labels = [row[label_index] for row in data]\n",
    "    \n",
    "    if not labels:\n",
    "        return Node(label=None)\n",
    "    \n",
    "    if len(set(labels)) == 1:\n",
    "        return Node(label=labels[0])\n",
    "    \n",
    "    if len(attributes) == 0 or (max_depth is not None and max_depth <= 0):\n",
    "        return Node(label=max(set(labels), key=labels.count))\n",
    "    \n",
    "    best_attribute, threshold = choose_best_attribute(data, attributes, label_index, criterion)\n",
    "    node = Node(attribute=best_attribute, threshold=threshold)\n",
    "    \n",
    "    if threshold is not None:\n",
    "        left_subset = [row for row in data if row[best_attribute] != 'unknown' and float(row[best_attribute]) <= threshold]\n",
    "        right_subset = [row for row in data if row[best_attribute] != 'unknown' and float(row[best_attribute]) > threshold]\n",
    "        if left_subset:\n",
    "            node.branches[f\"<={threshold}\"] = id3(left_subset, attributes, label_index, max_depth-1 if max_depth is not None else None, criterion)\n",
    "        if right_subset:\n",
    "            node.branches[f\">{threshold}\"] = id3(right_subset, attributes, label_index, max_depth-1 if max_depth is not None else None, criterion)\n",
    "    else:\n",
    "        for value in set(row[best_attribute] for row in data if row[best_attribute] != 'unknown'):\n",
    "            subset = [row for row in data if row[best_attribute] == value]\n",
    "            if subset:\n",
    "                node.branches[value] = id3(subset, attributes, label_index, max_depth-1 if max_depth is not None else None, criterion)\n",
    "    \n",
    "    if not node.branches:\n",
    "        return Node(label=max(set(labels), key=labels.count))\n",
    "    \n",
    "    return node\n",
    "\n",
    "def predict(node, instance):\n",
    "    if node.label is not None:\n",
    "        return node.label\n",
    "    if node.attribute >= len(instance):\n",
    "        return None\n",
    "    value = instance[node.attribute]\n",
    "    if node.threshold is not None:\n",
    "        if value == 'unknown':\n",
    "            return None\n",
    "        if float(value) <= node.threshold:\n",
    "            branch = f\"<={node.threshold}\"\n",
    "        else:\n",
    "            branch = f\">{node.threshold}\"\n",
    "    else:\n",
    "        branch = value\n",
    "    if branch not in node.branches:\n",
    "        return None\n",
    "    return predict(node.branches[branch], instance)\n",
    "\n",
    "def bootstrap_sample(data):\n",
    "    n_samples = len(data)\n",
    "    return [data[np.random.randint(n_samples)] for _ in range(n_samples)]\n",
    "\n",
    "def load_data(filename):\n",
    "    data = np.genfromtxt(filename, delimiter=',', dtype=str)\n",
    "    return data.tolist()\n",
    "\n",
    "def bagged_trees(data, n_trees, max_depth):\n",
    "    label_index = len(data[0]) - 1\n",
    "    attributes = list(range(len(data[0]) - 1))\n",
    "    \n",
    "    trees = []\n",
    "    for _ in range(n_trees):\n",
    "        sample = bootstrap_sample(data)\n",
    "        tree = id3(sample, attributes, label_index, max_depth)\n",
    "        trees.append(tree)\n",
    "    \n",
    "    return trees\n",
    "\n",
    "def bagged_predict(trees, instance):\n",
    "    predictions = [predict(tree, instance) for tree in trees]\n",
    "    predictions = [p for p in predictions if p is not None]\n",
    "    return max(set(predictions), key=predictions.count) if predictions else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data('train_bank.csv')\n",
    "test_data = load_data('test_bank.csv')\n",
    "\n",
    "# Experiment\n",
    "n_repeats = 100\n",
    "n_samples = 1000\n",
    "n_trees = 500\n",
    "\n",
    "single_tree_predictions = []\n",
    "bagged_tree_predictions = []\n",
    "\n",
    "for _ in range(n_repeats):\n",
    "    sampled_data = np.random.choice(len(train_data), n_samples, replace=False)\n",
    "    sampled_data = [train_data[i] for i in sampled_data]\n",
    "    \n",
    "    trees = bagged_trees(sampled_data, n_trees, max_depth=None)\n",
    "    \n",
    "    single_tree_predictions.append([predict(trees[0], instance) for instance in test_data])\n",
    "    bagged_tree_predictions.append([bagged_predict(trees, instance) for instance in test_data])\n",
    "\n",
    "true_labels = np.array([1 if instance[-1] == 'yes' else 0 for instance in test_data])\n",
    "single_tree_predictions = np.array([[1 if pred == 'yes' else 0 for pred in preds] for preds in single_tree_predictions])\n",
    "bagged_tree_predictions = np.array([[1 if pred == 'yes' else 0 for pred in preds] for preds in bagged_tree_predictions])\n",
    "\n",
    "single_tree_mean_pred = np.mean(single_tree_predictions, axis=0)\n",
    "single_tree_bias = np.mean((single_tree_mean_pred - true_labels) ** 2)\n",
    "single_tree_variance = np.mean(np.var(single_tree_predictions, axis=0))\n",
    "single_tree_error = single_tree_bias + single_tree_variance\n",
    "\n",
    "bagged_tree_mean_pred = np.mean(bagged_tree_predictions, axis=0)\n",
    "bagged_tree_bias = np.mean((bagged_tree_mean_pred - true_labels) ** 2)\n",
    "bagged_tree_variance = np.mean(np.var(bagged_tree_predictions, axis=0))\n",
    "bagged_tree_error = bagged_tree_bias + bagged_tree_variance\n",
    "\n",
    "print(\"Single Tree Results:\")\n",
    "print(f\"Bias: {single_tree_bias:.4f}\")\n",
    "print(f\"Variance: {single_tree_variance:.4f}\")\n",
    "print(f\"General Squared Error: {single_tree_error:.4f}\")\n",
    "\n",
    "print(\"\\nBagged Trees Results:\")\n",
    "print(f\"Bias: {bagged_tree_bias:.4f}\")\n",
    "print(f\"Variance: {bagged_tree_variance:.4f}\")\n",
    "print(f\"General Squared Error: {bagged_tree_error:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
