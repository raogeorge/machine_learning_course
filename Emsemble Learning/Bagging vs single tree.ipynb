{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def load_data(filename):\n",
    "    data = np.genfromtxt(filename, delimiter=',', dtype=str)\n",
    "   \n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "   \n",
    "    X_encoded = np.zeros(X.shape, dtype=float)\n",
    "    for i in range(X.shape[1]):\n",
    "        try:\n",
    "            X_encoded[:, i] = X[:, i].astype(float)\n",
    "        except ValueError:\n",
    "            unique_values = np.unique(X[:, i])\n",
    "            X_encoded[:, i] = np.array([np.where(unique_values == val)[0][0] for val in X[:, i]])\n",
    "   \n",
    "    y = (y == 'yes').astype(int) * 2 - 1\n",
    "   \n",
    "    return X_encoded, y\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "def entropy(y):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "\n",
    "def information_gain(parent, left_child, right_child):\n",
    "    weight_left = len(left_child) / len(parent)\n",
    "    weight_right = len(right_child) / len(parent)\n",
    "    return entropy(parent) - (weight_left * entropy(left_child) + weight_right * entropy(right_child))\n",
    "\n",
    "def best_split(X, y):\n",
    "    best_gain = -1\n",
    "    best_feature, best_threshold = None, None\n",
    "    \n",
    "    for feature in range(X.shape[1]):\n",
    "        thresholds = np.unique(X[:, feature])\n",
    "        for threshold in thresholds:\n",
    "            left_mask = X[:, feature] <= threshold\n",
    "            right_mask = ~left_mask\n",
    "            gain = information_gain(y, y[left_mask], y[right_mask])\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature\n",
    "                best_threshold = threshold\n",
    "    \n",
    "    return best_feature, best_threshold\n",
    "\n",
    "def build_tree(X, y, max_depth=None, depth=0):\n",
    "    if len(np.unique(y)) == 1 or (max_depth is not None and depth == max_depth):\n",
    "        return Node(value=np.mean(y))\n",
    "    \n",
    "    feature, threshold = best_split(X, y)\n",
    "    \n",
    "    if feature is None:\n",
    "        return Node(value=np.mean(y))\n",
    "    \n",
    "    left_mask = X[:, feature] <= threshold\n",
    "    right_mask = ~left_mask\n",
    "    \n",
    "    left_subtree = build_tree(X[left_mask], y[left_mask], max_depth, depth + 1)\n",
    "    right_subtree = build_tree(X[right_mask], y[right_mask], max_depth, depth + 1)\n",
    "    \n",
    "    return Node(feature=feature, threshold=threshold, left=left_subtree, right=right_subtree)\n",
    "\n",
    "def predict(node, x):\n",
    "    if node.value is not None:\n",
    "        return node.value\n",
    "    if x[node.feature] <= node.threshold:\n",
    "        return predict(node.left, x)\n",
    "    else:\n",
    "        return predict(node.right, x)\n",
    "\n",
    "def bagged_trees(X, y, n_trees, max_depth=None):\n",
    "    trees = []\n",
    "    for _ in range(n_trees):\n",
    "        indices = np.random.choice(len(X), len(X), replace=True)\n",
    "        X_sample, y_sample = X[indices], y[indices]\n",
    "        tree = build_tree(X_sample, y_sample, max_depth)\n",
    "        trees.append(tree)\n",
    "    return trees\n",
    "\n",
    "def bagged_predict(trees, x):\n",
    "    predictions = [predict(tree, x) for tree in trees]\n",
    "    return np.mean(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train, y_train = load_data('train_bank.csv')\n",
    "X_test, y_test = load_data('test_bank.csv')\n",
    "\n",
    "# Experiment parameters\n",
    "n_repeats = 100\n",
    "n_samples = 1000\n",
    "n_trees = 500\n",
    "\n",
    "single_tree_predictions = []\n",
    "bagged_tree_predictions = []\n",
    "\n",
    "for _ in range(n_repeats):\n",
    "    # Sample 1,000 examples without replacement\n",
    "    indices = np.random.choice(len(X_train), n_samples, replace=False)\n",
    "    X_sample, y_sample = X_train[indices], y_train[indices]\n",
    "    \n",
    "    # Train bagged trees\n",
    "    trees = bagged_trees(X_sample, y_sample, n_trees)\n",
    "    \n",
    "    # Store predictions\n",
    "    single_tree_predictions.append([predict(trees[0], x) for x in X_test])\n",
    "    bagged_tree_predictions.append([bagged_predict(trees, x) for x in X_test])\n",
    "\n",
    "single_tree_predictions = np.array(single_tree_predictions)\n",
    "bagged_tree_predictions = np.array(bagged_tree_predictions)\n",
    "\n",
    "def compute_bias_variance(predictions, true_labels):\n",
    "    mean_pred = np.mean(predictions, axis=0)\n",
    "    bias = np.mean((mean_pred - true_labels) ** 2)\n",
    "    variance = np.mean(np.var(predictions, axis=0, ddof=1))\n",
    "    return bias, variance\n",
    "\n",
    "single_tree_bias, single_tree_variance = compute_bias_variance(single_tree_predictions, y_test)\n",
    "bagged_tree_bias, bagged_tree_variance = compute_bias_variance(bagged_tree_predictions, y_test)\n",
    "\n",
    "single_tree_error = single_tree_bias + single_tree_variance\n",
    "bagged_tree_error = bagged_tree_bias + bagged_tree_variance\n",
    "\n",
    "print(\"Single Tree Results:\")\n",
    "print(f\"Bias: {single_tree_bias:.4f}\")\n",
    "print(f\"Variance: {single_tree_variance:.4f}\")\n",
    "print(f\"General Squared Error: {single_tree_error:.4f}\")\n",
    "\n",
    "print(\"\\nBagged Trees Results:\")\n",
    "print(f\"Bias: {bagged_tree_bias:.4f}\")\n",
    "print(f\"Variance: {bagged_tree_variance:.4f}\")\n",
    "print(f\"General Squared Error: {bagged_tree_error:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
