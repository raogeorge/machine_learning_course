{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, attribute=None, threshold=None, label=None, branches=None):\n",
    "        self.attribute = attribute\n",
    "        self.threshold = threshold\n",
    "        self.label = label\n",
    "        self.branches = branches or {}\n",
    "\n",
    "def entropy(data, label_index):\n",
    "    labels = [row[label_index] for row in data]\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts / len(labels)\n",
    "    return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "\n",
    "def information_gain(data, attribute, label_index, criterion='info_gain'):\n",
    "    total_entropy = entropy(data, label_index)\n",
    "    weighted_entropy = 0\n",
    "    \n",
    "    if isinstance(data[0][attribute], (int, float)):\n",
    "        values = [float(row[attribute]) for row in data if row[attribute] != 'unknown']\n",
    "        threshold = np.median(values)\n",
    "        left_subset = [row for row in data if row[attribute] != 'unknown' and float(row[attribute]) <= threshold]\n",
    "        right_subset = [row for row in data if row[attribute] != 'unknown' and float(row[attribute]) > threshold]\n",
    "        \n",
    "        if left_subset:\n",
    "            weighted_entropy += len(left_subset) / len(data) * entropy(left_subset, label_index)\n",
    "        if right_subset:\n",
    "            weighted_entropy += len(right_subset) / len(data) * entropy(right_subset, label_index)\n",
    "    else:\n",
    "        for value in set(row[attribute] for row in data if row[attribute] != 'unknown'):\n",
    "            subset = [row for row in data if row[attribute] == value]\n",
    "            weighted_entropy += len(subset) / len(data) * entropy(subset, label_index)\n",
    "    \n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def choose_best_attribute(data, attributes, label_index, criterion='info_gain'):\n",
    "    best_gain = -float('inf')\n",
    "    best_attribute = None\n",
    "    best_threshold = None\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        gain = information_gain(data, attribute, label_index, criterion)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_attribute = attribute\n",
    "            if isinstance(data[0][attribute], (int, float)):\n",
    "                values = [float(row[attribute]) for row in data if row[attribute] != 'unknown']\n",
    "                best_threshold = np.median(values)\n",
    "    \n",
    "    return best_attribute, best_threshold\n",
    "\n",
    "def id3(data, attributes, label_index, max_depth, criterion='info_gain'):\n",
    "    labels = [row[label_index] for row in data]\n",
    "    \n",
    "    if not labels:\n",
    "        return Node(label=None)\n",
    "    \n",
    "    if len(set(labels)) == 1:\n",
    "        return Node(label=labels[0])\n",
    "    \n",
    "    if len(attributes) == 0 or (max_depth is not None and max_depth <= 0):\n",
    "        return Node(label=max(set(labels), key=labels.count))\n",
    "    \n",
    "    best_attribute, threshold = choose_best_attribute(data, attributes, label_index, criterion)\n",
    "    node = Node(attribute=best_attribute, threshold=threshold)\n",
    "    \n",
    "    if threshold is not None:\n",
    "        left_subset = [row for row in data if row[best_attribute] != 'unknown' and float(row[best_attribute]) <= threshold]\n",
    "        right_subset = [row for row in data if row[best_attribute] != 'unknown' and float(row[best_attribute]) > threshold]\n",
    "        if left_subset:\n",
    "            node.branches[f\"<={threshold}\"] = id3(left_subset, attributes, label_index, max_depth-1 if max_depth is not None else None, criterion)\n",
    "        if right_subset:\n",
    "            node.branches[f\">{threshold}\"] = id3(right_subset, attributes, label_index, max_depth-1 if max_depth is not None else None, criterion)\n",
    "    else:\n",
    "        for value in set(row[best_attribute] for row in data if row[best_attribute] != 'unknown'):\n",
    "            subset = [row for row in data if row[best_attribute] == value]\n",
    "            if subset:\n",
    "                node.branches[value] = id3(subset, attributes, label_index, max_depth-1 if max_depth is not None else None, criterion)\n",
    "    \n",
    "    if not node.branches:\n",
    "        return Node(label=max(set(labels), key=labels.count))\n",
    "    \n",
    "    return node\n",
    "\n",
    "def predict(node, instance):\n",
    "    if node.label is not None:\n",
    "        return node.label\n",
    "    if node.attribute >= len(instance):\n",
    "        return None\n",
    "    value = instance[node.attribute]\n",
    "    if node.threshold is not None:\n",
    "        if value == 'unknown':\n",
    "            return None\n",
    "        if float(value) <= node.threshold:\n",
    "            branch = f\"<={node.threshold}\"\n",
    "        else:\n",
    "            branch = f\">{node.threshold}\"\n",
    "    else:\n",
    "        branch = value\n",
    "    if branch not in node.branches:\n",
    "        return None\n",
    "    return predict(node.branches[branch], instance)\n",
    "\n",
    "def bootstrap_sample(data):\n",
    "    n_samples = len(data)\n",
    "    return [data[np.random.randint(n_samples)] for _ in range(n_samples)]\n",
    "\n",
    "def bagged_trees(data, n_trees, max_depth):\n",
    "    label_index = len(data[0]) - 1\n",
    "    attributes = list(range(len(data[0]) - 1))\n",
    "    \n",
    "    trees = []\n",
    "    for _ in range(n_trees):\n",
    "        sample = bootstrap_sample(data)\n",
    "        tree = id3(sample, attributes, label_index, max_depth)\n",
    "        trees.append(tree)\n",
    "    \n",
    "    return trees\n",
    "\n",
    "def bagged_predict(trees, instance):\n",
    "    predictions = [predict(tree, instance) for tree in trees]\n",
    "    predictions = [p for p in predictions if p is not None]\n",
    "    return max(set(predictions), key=predictions.count) if predictions else None\n",
    "\n",
    "def load_data(filename):\n",
    "    data = np.genfromtxt(filename, delimiter=',', dtype=str)\n",
    "    return data.tolist()\n",
    "\n",
    "def compute_bias_variance(predictions, y_true):\n",
    "    y_true = np.array(y_true)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    mean_pred = np.mean(predictions, axis=0)\n",
    "    bias = np.mean((mean_pred - y_true) ** 2)\n",
    "    variance = np.mean(np.var(predictions, axis=0))\n",
    "    \n",
    "    return bias, variance\n",
    "\n",
    "# Load and preprocess data\n",
    "train_data = load_data('train_bank.csv')\n",
    "test_data = load_data('test_bank.csv')\n",
    "\n",
    "# Replace unknown values\n",
    "for dataset in [train_data, test_data]:\n",
    "    for attr in range(len(dataset[0]) - 1):\n",
    "        known_values = [row[attr] for row in dataset if row[attr] != 'unknown']\n",
    "        if known_values:\n",
    "            majority = max(set(known_values), key=known_values.count)\n",
    "            for row in dataset:\n",
    "                if row[attr] == 'unknown':\n",
    "                    row[attr] = majority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiment\n",
    "n_repeats = 100\n",
    "n_samples = 1000\n",
    "n_trees = 500\n",
    "\n",
    "single_tree_predictions = []\n",
    "bagged_tree_predictions = []\n",
    "\n",
    "for _ in range(n_repeats):\n",
    "    # Sample data\n",
    "    sample_indices = np.random.choice(len(train_data), n_samples, replace=False)\n",
    "    sample_data = [train_data[i] for i in sample_indices]\n",
    "    \n",
    "    # Train single tree\n",
    "    single_tree = id3(sample_data, list(range(len(sample_data[0]) - 1)), -1, max_depth=None)\n",
    "    single_tree_predictions.append([predict(single_tree, instance) for instance in test_data])\n",
    "    \n",
    "    # Train bagged trees\n",
    "    trees = bagged_trees(sample_data, n_trees, max_depth=None)\n",
    "    bagged_tree_predictions.append([bagged_predict(trees, instance) for instance in test_data])\n",
    "\n",
    "# Compute bias and variance\n",
    "y_true = [instance[-1] for instance in test_data]\n",
    "\n",
    "single_tree_bias, single_tree_variance = compute_bias_variance(single_tree_predictions, y_true)\n",
    "bagged_tree_bias, bagged_tree_variance = compute_bias_variance(bagged_tree_predictions, y_true)\n",
    "\n",
    "# Compute general squared error\n",
    "single_tree_error = single_tree_bias + single_tree_variance\n",
    "bagged_tree_error = bagged_tree_bias + bagged_tree_variance\n",
    "\n",
    "print(\"Single Tree Results:\")\n",
    "print(f\"Bias: {single_tree_bias:.4f}\")\n",
    "print(f\"Variance: {single_tree_variance:.4f}\")\n",
    "print(f\"General Squared Error: {single_tree_error:.4f}\")\n",
    "\n",
    "print(\"\\nBagged Trees Results:\")\n",
    "print(f\"Bias: {bagged_tree_bias:.4f}\")\n",
    "print(f\"Variance: {bagged_tree_variance:.4f}\")\n",
    "print(f\"General Squared Error: {bagged_tree_error:.4f}\")\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "print(\"Bagged trees typically have lower variance and slightly higher bias compared to single trees.\")\n",
    "print(\"The overall error is usually lower for bagged trees due to the significant reduction in variance.\")\n",
    "print(\"This demonstrates the effectiveness of the bagging approach in reducing overfitting and improving generalization.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
