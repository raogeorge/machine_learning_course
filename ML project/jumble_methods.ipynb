{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#In[]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import  StandardScaler,MinMaxScaler,OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(\"datasets/train_final.csv\")\n",
    "test_data = pd.read_csv(\"datasets/test_final.csv\")\n",
    "\n",
    "#Preprocessing the data\n",
    "\n",
    "#In[]\n",
    "missing_features = []\n",
    "for i in train_data.columns:\n",
    "    count = sum(train_data[i]=='?')\n",
    "    if count>0:\n",
    "        missing_features.append(i)\n",
    "print(missing_features)\n",
    "\n",
    "#In[]\n",
    "def majority_features(feature):\n",
    "    yes_label = dict(train_data[train_data['income>50K']==1][feature].value_counts())\n",
    "    no_label = dict(train_data[train_data['income>50K']==0][feature].value_counts())\n",
    "    majority_fea_yes_label = sorted(yes_label,key=yes_label.get,reverse=True)[0]\n",
    "    majority_fea_no_label = sorted(no_label,key=no_label.get,reverse=True)[0]\n",
    "    return majority_fea_yes_label, majority_fea_no_label\n",
    "\n",
    "for feature in missing_features:\n",
    "    majority_features_yes, majority_features_no = majority_features(feature)\n",
    "    print(\"For the feature \"+feature+\". Majority is yes for \"+majority_features_yes+\". Majority is no for \"+majority_features_no)\n",
    "    yes_attr_data = train_data[train_data['income>50K']==1]\n",
    "    no_attr_data = train_data[train_data['income>50K']==0]\n",
    "    yes_attr_data[feature].replace('?',majority_features_yes,inplace=True)\n",
    "    no_attr_data[feature].replace('?',majority_features_no,inplace=True)\n",
    "    train_data = pd.concat([yes_attr_data,no_attr_data])\n",
    "    train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "#In[]\n",
    "train_data\n",
    "\n",
    "#In[]\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=train_data, x=\"age\", y=\"education.num\", hue=\"income>50K\", \n",
    "                palette=\"viridis\", alpha=0.7)\n",
    "\n",
    "plt.title(\"Age vs Education Number by Income\", fontsize=16)\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Education Number\", fontsize=12)\n",
    "plt.legend(title=\"Income > 50K\", title_fontsize='12', fontsize='10')\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#In[]\n",
    "sns.set_style(\"darkgrid\");\n",
    "sns.FacetGrid(train_data, hue=\"income>50K\", height=4) \\\n",
    "   .map(plt.scatter, \"hours.per.week\", \"education.num\") \\\n",
    "   .add_legend();\n",
    "plt.show();\n",
    "\n",
    "#In[]\n",
    "sns.set_style(\"darkgrid\");\n",
    "sns.FacetGrid(train_data, hue=\"income>50K\", height=4) \\\n",
    "   .map(plt.scatter, \"hours.per.week\", \"age\") \\\n",
    "   .add_legend();\n",
    "plt.show();\n",
    "    \n",
    "    \n",
    "#In[]\n",
    "Y_train_data = train_data['income>50K']\n",
    "X_train_data = train_data.drop('income>50K',axis=1)\n",
    "\n",
    "#In[]\n",
    "#As we see the majority is Private for work class for both yes and no label.\n",
    "#And native country is max for United States for both cases.\n",
    "# We take feature occupation is max for Other Service.\n",
    "test_data['workclass'] = test_data['workclass'].replace('?','Private')\n",
    "test_data['occupation'] = test_data['occupation'].replace('?','Other-service')\n",
    "test_data['native.country'] = test_data['native.country'].replace('?','United-States')\n",
    "\n",
    "#In[]\n",
    "ID = test_data['ID']\n",
    "X_test = test_data.drop('ID',axis=1)\n",
    "X_train,X_cv,Y_train,Y_cv = train_test_split(X_train_data,Y_train_data,test_size=0.15,random_state=42,stratify=Y_train_data)\n",
    "\n",
    "\n",
    "#In[]\n",
    "def preprocess_categorical(X_train, X_cv, X_test, column):\n",
    "    vectorizer = CountVectorizer()\n",
    "    train_pre = vectorizer.fit_transform(X_train[column].values.astype('U'))\n",
    "    cv_pre = vectorizer.transform(X_cv[column].values.astype('U'))\n",
    "    test_pre = vectorizer.transform(X_test[column].values.astype('U'))\n",
    "    return train_pre, cv_pre, test_pre\n",
    "\n",
    "def preprocess_numerical(X_train, X_cv, X_test, column):\n",
    "    scaler = StandardScaler()\n",
    "    train_pre = scaler.fit_transform(X_train[column].values.reshape(-1, 1))\n",
    "    cv_pre = scaler.transform(X_cv[column].values.reshape(-1, 1))\n",
    "    test_pre = scaler.transform(X_test[column].values.reshape(-1, 1))\n",
    "    return train_pre, cv_pre, test_pre\n",
    "\n",
    "# Categorical columns\n",
    "cat_columns = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'native.country']\n",
    "cat_features = [preprocess_categorical(X_train, X_cv, X_test, col) for col in cat_columns]\n",
    "\n",
    "# Special case for 'sex' column\n",
    "sex_encoder = OneHotEncoder()\n",
    "sex_features = (\n",
    "    sex_encoder.fit_transform(X_train['sex'].values.reshape(-1, 1)),\n",
    "    sex_encoder.transform(X_cv['sex'].values.reshape(-1, 1)),\n",
    "    sex_encoder.transform(X_test['sex'].values.reshape(-1, 1))\n",
    ")\n",
    "\n",
    "# Numerical columns\n",
    "num_columns = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "num_features = [preprocess_numerical(X_train, X_cv, X_test, col) for col in num_columns]\n",
    "\n",
    "# Combine all features\n",
    "all_features = cat_features + [sex_features] + num_features\n",
    "X_train_preprocessed = hstack([feature[0] for feature in all_features])\n",
    "X_cv_preprocessed = hstack([feature[1] for feature in all_features])\n",
    "X_test_preprocessed = hstack([feature[2] for feature in all_features])\n",
    "\n",
    "#In[]\n",
    "X_train_preprocessed\n",
    "\n",
    "#In[]\n",
    "############XG Boost classifier###################\n",
    "print(\"XGB Classifier\")\n",
    "from xgboost import XGBClassifier\n",
    "weight = 6016/18984\n",
    "max_dept = [3]\n",
    "n_estimators = [200]\n",
    "# et = [0.2,0.5,0.7,0.9]\n",
    "# for e in [0.29,0.3,0.31]:\n",
    "#     for depth in max_dept:\n",
    "model = XGBClassifier(scale_pos_weight=weight,max_depth = 3, n_estimators=200,eta=0.3)\n",
    "model.fit(X_train_preprocessed, Y_train)\n",
    "\n",
    "yhat = model.predict_proba(X_train_preprocessed)\n",
    "final_pred = []\n",
    "for i in yhat:\n",
    "    if i[0]>i[1]:\n",
    "        final_pred.append(1-i[0])\n",
    "    else:\n",
    "        final_pred.append(i[1])\n",
    "mse = 0\n",
    "for i in range(len(Y_train)):\n",
    "    mse += (list(Y_train)[i]-final_pred[i])**2\n",
    "print(\"train mse\",mse/len(Y_train))\n",
    "\n",
    "#In[]\n",
    "# evaluate model\n",
    "yhat = model.predict_proba(X_cv_preprocessed)\n",
    "# pred_test\n",
    "final_pred = []\n",
    "for i in yhat:\n",
    "    if i[0]>i[1]:\n",
    "        final_pred.append(1-i[0])\n",
    "    else:\n",
    "        final_pred.append(i[1])\n",
    "mse = 0\n",
    "for i in range(len(Y_cv)):\n",
    "    mse += (list(Y_cv)[i]-final_pred[i])**2\n",
    "print(\"cv mse\",mse/len(Y_cv))\n",
    "\n",
    "#In[]\n",
    "\n",
    "model = XGBClassifier(scale_pos_weight=1-weight,max_depth = 3, n_estimators=200)\n",
    "model.fit(X_train_preprocessed, Y_train)\n",
    "\n",
    "yhat = model.predict_proba(X_test_preprocessed)\n",
    "\n",
    "# pred_test\n",
    "final_pred = []\n",
    "for i in yhat:\n",
    "    if i[0]>i[1]:\n",
    "        final_pred.append(1-i[0])\n",
    "    else:\n",
    "        final_pred.append(i[1])\n",
    "\n",
    "result = pd.DataFrame(columns=['ID','Prediction'])\n",
    "result['ID'] = ID\n",
    "result['Prediction'] = final_pred\n",
    "\n",
    "result.to_csv(\"prediction_xgbclassifer_1.csv\",index=False)\n",
    "\n",
    "#In[]:\n",
    "###################Linear Regression#####################\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_preprocessed,Y_train)\n",
    "train_pred = lr.predict(X_train_preprocessed)\n",
    "cv_pred = lr.predict(X_cv_preprocessed)\n",
    "\n",
    "mse = 0\n",
    "print(\"Linear Regression\")\n",
    "for i in range(len(Y_train)):\n",
    "    mse += (list(Y_train)[i]-train_pred[i])**2\n",
    "print(\"train mse\",mse/len(Y_cv))\n",
    "\n",
    "#In[]\n",
    "mse = 0\n",
    "for i in range(len(Y_cv)):\n",
    "    mse += (list(Y_cv)[i]-cv_pred[i])**2\n",
    "print(\"cv mse\",mse/len(Y_cv))\n",
    "\n",
    "#In[]\n",
    "pred_test = lr.predict(X_test_preprocessed)\n",
    "result = pd.DataFrame(columns=['ID','Prediction'])\n",
    "result['ID'] = ID\n",
    "result['Prediction'] = pred_test\n",
    "result.to_csv(\"prediction_linear_regression.csv\",index=False) \n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
