{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "train_data = pd.read_csv(\"train_final.csv\")\n",
    "test_data = pd.read_csv(\"test_final.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SGD Classification Results:\n",
      "===========================\n",
      "Model Parameters:\n",
      "Loss function: modified_huber\n",
      "Penalty: L2\n",
      "Learning rate: adaptive\n",
      "Class weights: balanced\n",
      "\n",
      "Cross-validation metrics:\n",
      "Accuracy:\n",
      "  Mean: 0.805 (+/- 0.006)\n",
      "Precision:\n",
      "  Mean: 0.563 (+/- 0.009)\n",
      "Recall:\n",
      "  Mean: 0.850 (+/- 0.021)\n",
      "F1:\n",
      "  Mean: 0.677 (+/- 0.012)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raoge\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [7] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define features\n",
    "numeric_features = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "categorical_features = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\n",
    "\n",
    "# Handle missing values\n",
    "def handle_missing_values(train_data, test_data):\n",
    "    train_cleaned = train_data.copy()\n",
    "    test_cleaned = test_data.copy()\n",
    "    \n",
    "    for feature in ['workclass', 'occupation', 'native.country']:\n",
    "        mode_value = train_data[feature][train_data[feature] != '?'].mode()[0]\n",
    "        train_cleaned[feature] = train_cleaned[feature].replace('?', mode_value)\n",
    "        test_cleaned[feature] = test_cleaned[feature].replace('?', mode_value)\n",
    "    \n",
    "    return train_cleaned, test_cleaned\n",
    "\n",
    "# Clean the data\n",
    "train_data_cleaned, test_data_cleaned = handle_missing_values(train_data, test_data)\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create SGD Classifier pipeline\n",
    "sgd_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SGDClassifier(\n",
    "        loss='modified_huber',      # Loss function with probability estimates\n",
    "        penalty='l2',               # L2 regularization to prevent overfitting\n",
    "        alpha=0.0001,              # Regularization strength\n",
    "        max_iter=1000,             # Maximum number of iterations\n",
    "        tol=1e-3,                  # Tolerance for stopping criterion\n",
    "        random_state=42,\n",
    "        learning_rate='adaptive',   # Adaptive learning rate\n",
    "        eta0=0.1,                  # Initial learning rate\n",
    "        early_stopping=True,        # Use early stopping\n",
    "        validation_fraction=0.1,    # Fraction of training data for early stopping\n",
    "        n_iter_no_change=5,        # Number of iterations with no improvement\n",
    "        class_weight='balanced'     # Handle class imbalance\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Prepare target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_data_cleaned['income>50K'])\n",
    "\n",
    "# Perform cross-validation with multiple metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(sgd_model, \n",
    "                          train_data_cleaned.drop('income>50K', axis=1), \n",
    "                          y_train, \n",
    "                          cv=5, \n",
    "                          scoring=scoring)\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"\\nSGD Classification Results:\")\n",
    "print(\"===========================\")\n",
    "print(\"Model Parameters:\")\n",
    "print(\"Loss function: modified_huber\")\n",
    "print(\"Penalty: L2\")\n",
    "print(\"Learning rate: adaptive\")\n",
    "print(\"Class weights: balanced\")\n",
    "print(\"\\nCross-validation metrics:\")\n",
    "for metric in scoring.keys():\n",
    "    scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric.capitalize()}:\")\n",
    "    print(f\"  Mean: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
    "\n",
    "# Fit the model on full training data\n",
    "sgd_model.fit(train_data_cleaned.drop('income>50K', axis=1), y_train)\n",
    "\n",
    "# Generate predictions for test data\n",
    "test_ids = test_data_cleaned['ID'].copy()\n",
    "test_predictions = sgd_model.predict(test_data_cleaned.drop('ID', axis=1))\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'income>50K': label_encoder.inverse_transform(test_predictions)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 0.807\n",
      "\n",
      "Detailed Classification Report (Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.79      0.86     18984\n",
      "           1       0.57      0.86      0.68      6016\n",
      "\n",
      "    accuracy                           0.81     25000\n",
      "   macro avg       0.76      0.82      0.77     25000\n",
      "weighted avg       0.85      0.81      0.82     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save predictions\n",
    "submission.to_csv('sgd_predictions.csv', index=False)\n",
    "\n",
    "# Print training accuracy\n",
    "train_predictions = sgd_model.predict(train_data_cleaned.drop('income>50K', axis=1))\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(f\"\\nTraining Accuracy: {train_accuracy:.3f}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nDetailed Classification Report (Training Set):\")\n",
    "print(classification_report(y_train, train_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
