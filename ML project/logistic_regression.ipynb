{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_data = pd.read_csv(\"train_final.csv\")\n",
    "test_data = pd.read_csv(\"test_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
      "       'marital.status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country',\n",
      "       'income>50K'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
      "       'marital.status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['workclass', 'occupation', 'native.country']\n",
      "['workclass', 'occupation', 'native.country']\n"
     ]
    }
   ],
   "source": [
    "# find out missing features between these two datasets\n",
    "missing_features = []\n",
    "for i in train_data.columns:\n",
    "    count = sum(train_data[i]=='?')\n",
    "    if count>0:\n",
    "        missing_features.append(i)\n",
    "print(missing_features)\n",
    "\n",
    "missing_test_features = []\n",
    "for i in test_data.columns:\n",
    "    count = sum(test_data[i]=='?')\n",
    "    if count>0:\n",
    "        missing_test_features.append(i)\n",
    "print(missing_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's handle missing values in both train and test data\n",
    "def handle_missing_values(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Replace '?' with mode for each categorical feature with missing values\n",
    "    for feature in ['workclass', 'occupation', 'native.country']:\n",
    "        # Calculate mode excluding '?' values\n",
    "        mode_value = data[feature][data[feature] != '?'].mode()[0]\n",
    "        data[feature] = data[feature].replace('?', mode_value)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Apply missing value handling\n",
    "train_data_cleaned = handle_missing_values(train_data)\n",
    "test_data_cleaned = handle_missing_values(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass: 0 '?' values remaining\n",
      "occupation: 0 '?' values remaining\n",
      "native.country: 0 '?' values remaining\n",
      "workclass: 0 '?' values remaining\n",
      "occupation: 0 '?' values remaining\n",
      "native.country: 0 '?' values remaining\n"
     ]
    }
   ],
   "source": [
    "# Test if there are missing value remaining\n",
    "for feature in ['workclass', 'occupation', 'native.country']:\n",
    "    q_count = sum(train_data_cleaned[feature] == '?')\n",
    "    print(f\"{feature}: {q_count} '?' values remaining\")\n",
    "\n",
    "for feature in ['workclass', 'occupation', 'native.country']:\n",
    "    q_count = sum(test_data_cleaned[feature] == '?')\n",
    "    print(f\"{feature}: {q_count} '?' values remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking all types of missing values:\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education.num     0\n",
      "marital.status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital.gain      0\n",
      "capital.loss      0\n",
      "hours.per.week    0\n",
      "native.country    0\n",
      "income>50K        0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 0\n",
      "ID                0\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education.num     0\n",
      "marital.status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital.gain      0\n",
      "capital.loss      0\n",
      "hours.per.week    0\n",
      "native.country    0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChecking all types of missing values:\")\n",
    "print(train_data_cleaned.isnull().sum())  # Checks for None/NaN\n",
    "print(\"\\nTotal missing values:\", train_data_cleaned.isnull().sum().sum())\n",
    "\n",
    "print(test_data_cleaned.isnull().sum())  # Checks for None/NaN\n",
    "print(\"\\nTotal missing values:\", test_data_cleaned.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation results:\n",
      "Accuracy:\n",
      "  Mean: 0.850 (+/- 0.010)\n",
      "Precision:\n",
      "  Mean: 0.736 (+/- 0.022)\n",
      "Recall:\n",
      "  Mean: 0.590 (+/- 0.030)\n",
      "F1:\n",
      "  Mean: 0.655 (+/- 0.026)\n",
      "\n",
      "Missing value counts before cleaning:\n",
      "workclass: 1437 missing values\n",
      "occupation: 1442 missing values\n",
      "native.country: 427 missing values\n",
      "\n",
      "Missing value counts after cleaning:\n",
      "workclass: 0 missing values\n",
      "occupation: 0 missing values\n",
      "native.country: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "# Separate features\n",
    "numeric_features = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "categorical_features = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create pipeline with LogisticRegression. Let's use logistic regression for this one.\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=2))\n",
    "])\n",
    "\n",
    "# Convert target to numeric\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_data_cleaned['income>50K'])\n",
    "\n",
    "# Perform cross-validation with multiple metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(model, \n",
    "                          train_data_cleaned.drop('income>50K', axis=1), \n",
    "                          y_train, \n",
    "                          cv=5, \n",
    "                          scoring=scoring)\n",
    "\n",
    "# Print detailed cross-validation results\n",
    "print(\"\\nCross-validation results:\")\n",
    "for metric in scoring.keys():\n",
    "    scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric.capitalize()}:\")\n",
    "    print(f\"  Mean: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
    "\n",
    "# Print missing value counts before and after cleaning\n",
    "print(\"\\nMissing value counts before cleaning:\")\n",
    "for feature in ['workclass', 'occupation', 'native.country']:\n",
    "    print(f\"{feature}: {sum(train_data[feature] == '?')} missing values\")\n",
    "\n",
    "print(\"\\nMissing value counts after cleaning:\")\n",
    "for feature in ['workclass', 'occupation', 'native.country']:\n",
    "    print(f\"{feature}: {sum(train_data_cleaned[feature] == '?')} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the model on full training data\n",
    "model.fit(train_data_cleaned.drop('income>50K', axis=1), y_train)\n",
    "\n",
    "# Generate predictions for test data\n",
    "test_ids = test_data_cleaned['ID'].copy()\n",
    "test_predictions = model.predict(test_data_cleaned.drop('ID', axis=1))\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'income>50K': label_encoder.inverse_transform(test_predictions)\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most important features:\n",
      "                              feature  importance\n",
      "3                        capital.gain    2.446761\n",
      "29  marital.status_Married-civ-spouse    1.954115\n",
      "28   marital.status_Married-AF-spouse    1.500919\n",
      "41         occupation_Priv-house-serv    1.440416\n",
      "89               native.country_South    1.239998\n",
      "75             native.country_Ireland    1.195318\n",
      "59            native.country_Columbia    1.147261\n",
      "51                  relationship_Wife    1.119608\n",
      "37         occupation_Farming-fishing    1.041549\n",
      "10         workclass_Self-emp-not-inc    1.022040\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis\n",
    "def get_feature_importance(pipeline, feature_names):\n",
    "    categorical_features_encoded = pipeline.named_steps['preprocessor']\\\n",
    "        .named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "    all_features = numeric_features + list(categorical_features_encoded)\n",
    "    \n",
    "    coefficients = pipeline.named_steps['classifier'].coef_[0]\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': all_features,\n",
    "        'importance': np.abs(coefficients)\n",
    "    })\n",
    "    \n",
    "    return feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Print feature importance\n",
    "print(\"\\nMost important features:\")\n",
    "feature_importance = get_feature_importance(model, numeric_features + categorical_features)\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "submission.to_csv('income_predictions_logistic_regression.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
